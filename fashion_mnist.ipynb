{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense ,Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import BatchNormalization ,Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist =tf.keras.datasets.fashion_mnist\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images / 255.0\n",
    "train_labels = to_categorical(train_labels) \n",
    "test_images = test_images / 255.0\n",
    "test_labels = to_categorical(test_labels)\n",
    "\n",
    "trainX = train_images.reshape((train_images.shape[0], 28, 28, 1))\n",
    "testX = test_images.reshape((test_images.shape[0], 28, 28, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000, 10)\n",
      "(10000, 28, 28)\n",
      "(10000, 10)\n",
      "(60000, 28, 28, 1)\n",
      "(10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(train_images))\n",
    "print(np.shape(train_labels))\n",
    "print(np.shape(test_images))\n",
    "print(np.shape(test_labels))\n",
    "print(np.shape(trainX))\n",
    "print(np.shape(testX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_feedforward():\n",
    "    model =Sequential()\n",
    "    model.add(Flatten(input_shape=(28,28)))\n",
    "    model.add(Dense(128,activation=\"relu\"))\n",
    "    model.add(Dense(10,activation=\"softmax\"))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_convolution():\n",
    "    \n",
    "    \n",
    "    model =Sequential()\n",
    "    model.add(Conv2D(32,kernel_size=(2,2),input_shape=(28,28,1),activation=\"relu\")) #27\n",
    "    model.add(Conv2D(32,kernel_size=(2,2),activation=\"relu\")) #26\n",
    "    model.add(MaxPooling2D(pool_size=(2,2))) #13\n",
    "    model.add(Conv2D(64,kernel_size=(2,2),activation=\"relu\")) #12  \n",
    "    model.add(MaxPooling2D(pool_size=(2,2))) #6\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64,activation=\"relu\"))\n",
    "    model.add(Dense(10,activation=\"softmax\"))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(i):\n",
    "    if i==1:\n",
    "        model = get_model_feedforward()\n",
    "    elif i==2:\n",
    "        model = get_model_convolution()\n",
    "        \n",
    "    optimizer = tf.keras.optimizers.Adam(lr=0.005)\n",
    "    model.compile(optimizer=optimizer,loss=\"categorical_crossentropy\", metrics=['accuracy'])\n",
    "             \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/10\n",
      "54000/54000 [==============================] - 65s 1ms/sample - loss: 0.4035 - accuracy: 0.8544 - val_loss: 0.3215 - val_accuracy: 0.8800\n",
      "Epoch 2/10\n",
      "54000/54000 [==============================] - 59s 1ms/sample - loss: 0.2793 - accuracy: 0.8976 - val_loss: 0.2652 - val_accuracy: 0.8993\n",
      "Epoch 3/10\n",
      "54000/54000 [==============================] - 38s 702us/sample - loss: 0.2426 - accuracy: 0.9093 - val_loss: 0.2773 - val_accuracy: 0.9030\n",
      "Epoch 4/10\n",
      "54000/54000 [==============================] - 42s 785us/sample - loss: 0.2215 - accuracy: 0.9178 - val_loss: 0.2744 - val_accuracy: 0.9047\n",
      "Epoch 5/10\n",
      "54000/54000 [==============================] - 46s 852us/sample - loss: 0.2072 - accuracy: 0.9235 - val_loss: 0.2417 - val_accuracy: 0.9155\n",
      "Epoch 6/10\n",
      "54000/54000 [==============================] - 47s 879us/sample - loss: 0.1918 - accuracy: 0.9284 - val_loss: 0.2698 - val_accuracy: 0.9045\n",
      "Epoch 7/10\n",
      "54000/54000 [==============================] - 39s 713us/sample - loss: 0.1819 - accuracy: 0.9331 - val_loss: 0.2609 - val_accuracy: 0.9140\n",
      "Epoch 8/10\n",
      "54000/54000 [==============================] - 41s 756us/sample - loss: 0.1749 - accuracy: 0.9353 - val_loss: 0.2772 - val_accuracy: 0.9093\n",
      "Epoch 9/10\n",
      "54000/54000 [==============================] - 48s 890us/sample - loss: 0.1638 - accuracy: 0.9390 - val_loss: 0.3029 - val_accuracy: 0.9002\n",
      "Epoch 10/10\n",
      "54000/54000 [==============================] - 50s 924us/sample - loss: 0.1615 - accuracy: 0.9396 - val_loss: 0.2882 - val_accuracy: 0.9068\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fb9145e1090>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.fit(trainX, train_labels,epochs=10,validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 2s 242us/sample - loss: 0.3212 - accuracy: 0.9012\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3212257546544075, 0.9012]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(testX,test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "feed forword network -> [0.3965493327856064, 0.8655] <br>\n",
    "convolutional network -> [0.3212257546544075, 0.9012]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
